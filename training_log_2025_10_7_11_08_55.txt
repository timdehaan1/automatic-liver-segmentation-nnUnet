
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-10-07 11:08:55.165020: do_dummy_2d_data_aug: True 
2025-10-07 11:08:55.165842: Using splits from existing split file: /home/rnga/tsdehaan/my-scratch/Data_nnUNet/nnUnet_preprocessed/Dataset001_AAA/splits_final.json 
2025-10-07 11:08:55.166034: The split file contains 5 splits. 
2025-10-07 11:08:55.166084: Desired fold for training: 0 
2025-10-07 11:08:55.166127: This split has 61 training and 16 validation cases. 
2025-10-07 11:09:00.801270: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 3, 'patch_size': [28, 192, 256], 'median_image_size_in_voxels': [27.0, 168.0, 256.0], 'spacing': [7.0, 1.7578125, 1.7578125], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_AAA', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [7.0, 1.7578125, 1.7578125], 'original_median_shape_after_transp': [27, 168, 256], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2868.689453125, 'mean': 227.654052734375, 'median': 202.5998992919922, 'min': 16.920146942138672, 'percentile_00_5': 53.70329284667969, 'percentile_99_5': 852.1956787109375, 'std': 123.62262725830078}}} 
 
2025-10-07 11:09:03.734222: unpacking dataset... 
2025-10-07 11:09:16.887197: unpacking done... 
2025-10-07 11:09:16.889297: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-10-07 11:09:16.966013:  
2025-10-07 11:09:16.966149: Epoch 0 
2025-10-07 11:09:16.966361: Current learning rate: 0.01 
2025-10-07 11:12:18.829184: train_loss -0.5312 
2025-10-07 11:12:18.829574: val_loss -0.6653 
2025-10-07 11:12:18.829694: Pseudo dice [0.7807] 
2025-10-07 11:12:18.829825: Epoch time: 181.87 s 
2025-10-07 11:12:18.829892: Yayy! New best EMA pseudo Dice: 0.7807 
2025-10-07 11:12:20.479833:  
2025-10-07 11:12:20.480086: Epoch 1 
2025-10-07 11:12:20.480212: Current learning rate: 0.00995 
2025-10-07 11:15:00.847085: train_loss -0.6763 
2025-10-07 11:15:00.847414: val_loss -0.732 
2025-10-07 11:15:00.847491: Pseudo dice [0.817] 
2025-10-07 11:15:00.847598: Epoch time: 160.37 s 
2025-10-07 11:15:00.847700: Yayy! New best EMA pseudo Dice: 0.7843 
2025-10-07 11:15:02.572252:  
2025-10-07 11:15:02.572484: Epoch 2 
2025-10-07 11:15:02.572605: Current learning rate: 0.00991 
2025-10-07 11:17:42.283307: train_loss -0.7221 
2025-10-07 11:17:42.283849: val_loss -0.7329 
2025-10-07 11:17:42.283927: Pseudo dice [0.816] 
2025-10-07 11:17:42.284017: Epoch time: 159.71 s 
2025-10-07 11:17:42.284082: Yayy! New best EMA pseudo Dice: 0.7875 
2025-10-07 11:17:44.197844:  
2025-10-07 11:17:44.198049: Epoch 3 
2025-10-07 11:17:44.198165: Current learning rate: 0.00986 
2025-10-07 11:20:24.037680: train_loss -0.7329 
2025-10-07 11:20:24.038038: val_loss -0.7473 
2025-10-07 11:20:24.038121: Pseudo dice [0.8258] 
2025-10-07 11:20:24.038208: Epoch time: 159.84 s 
2025-10-07 11:20:24.038275: Yayy! New best EMA pseudo Dice: 0.7913 
2025-10-07 11:20:25.810801:  
2025-10-07 11:20:25.811021: Epoch 4 
2025-10-07 11:20:25.811145: Current learning rate: 0.00982 
2025-10-07 11:23:05.747699: train_loss -0.7424 
2025-10-07 11:23:05.748045: val_loss -0.7481 
2025-10-07 11:23:05.748129: Pseudo dice [0.8281] 
2025-10-07 11:23:05.748216: Epoch time: 159.94 s 
2025-10-07 11:23:05.748279: Yayy! New best EMA pseudo Dice: 0.795 
2025-10-07 11:23:07.578691:  
2025-10-07 11:23:07.578926: Epoch 5 
2025-10-07 11:23:07.579058: Current learning rate: 0.00977 
2025-10-07 11:25:47.493394: train_loss -0.749 
2025-10-07 11:25:47.493732: val_loss -0.7564 
2025-10-07 11:25:47.493824: Pseudo dice [0.8309] 
2025-10-07 11:25:47.493914: Epoch time: 159.92 s 
2025-10-07 11:25:47.493977: Yayy! New best EMA pseudo Dice: 0.7986 
2025-10-07 11:25:49.248912:  
2025-10-07 11:25:49.249129: Epoch 6 
2025-10-07 11:25:49.249247: Current learning rate: 0.00973 
2025-10-07 11:28:29.249075: train_loss -0.7593 
2025-10-07 11:28:29.249413: val_loss -0.7569 
2025-10-07 11:28:29.249493: Pseudo dice [0.8326] 
2025-10-07 11:28:29.249580: Epoch time: 160.0 s 
2025-10-07 11:28:29.249644: Yayy! New best EMA pseudo Dice: 0.802 
2025-10-07 11:28:31.107465:  
2025-10-07 11:28:31.107685: Epoch 7 
2025-10-07 11:28:31.107813: Current learning rate: 0.00968 
2025-10-07 11:31:11.183105: train_loss -0.7581 
2025-10-07 11:31:11.183467: val_loss -0.765 
2025-10-07 11:31:11.183597: Pseudo dice [0.8352] 
2025-10-07 11:31:11.183705: Epoch time: 160.08 s 
2025-10-07 11:31:11.183771: Yayy! New best EMA pseudo Dice: 0.8053 
2025-10-07 11:31:12.981043:  
2025-10-07 11:31:12.981285: Epoch 8 
2025-10-07 11:31:12.981462: Current learning rate: 0.00964 
2025-10-07 11:33:53.027071: train_loss -0.763 
2025-10-07 11:33:53.027414: val_loss -0.7703 
2025-10-07 11:33:53.027514: Pseudo dice [0.8427] 
2025-10-07 11:33:53.027614: Epoch time: 160.05 s 
2025-10-07 11:33:53.027696: Yayy! New best EMA pseudo Dice: 0.809 
2025-10-07 11:33:54.861398:  
2025-10-07 11:33:54.861599: Epoch 9 
2025-10-07 11:33:54.861724: Current learning rate: 0.00959 
2025-10-07 11:36:34.993831: train_loss -0.7735 
2025-10-07 11:36:34.994192: val_loss -0.7663 
2025-10-07 11:36:34.994276: Pseudo dice [0.8349] 
2025-10-07 11:36:34.994360: Epoch time: 160.13 s 
2025-10-07 11:36:34.994424: Yayy! New best EMA pseudo Dice: 0.8116 
2025-10-07 11:36:37.083466:  
2025-10-07 11:36:37.083698: Epoch 10 
2025-10-07 11:36:37.083826: Current learning rate: 0.00955 
2025-10-07 11:39:17.035194: train_loss -0.7662 
2025-10-07 11:39:17.035559: val_loss -0.7582 
2025-10-07 11:39:17.035645: Pseudo dice [0.8343] 
2025-10-07 11:39:17.035747: Epoch time: 159.95 s 
2025-10-07 11:39:17.035812: Yayy! New best EMA pseudo Dice: 0.8139 
2025-10-07 11:39:18.782603:  
2025-10-07 11:39:18.782832: Epoch 11 
2025-10-07 11:39:18.782958: Current learning rate: 0.0095 
2025-10-07 11:41:59.007115: train_loss -0.7746 
2025-10-07 11:41:59.007450: val_loss -0.767 
2025-10-07 11:41:59.007532: Pseudo dice [0.8377] 
2025-10-07 11:41:59.007620: Epoch time: 160.23 s 
2025-10-07 11:41:59.007713: Yayy! New best EMA pseudo Dice: 0.8163 
2025-10-07 11:42:00.848190:  
2025-10-07 11:42:00.848427: Epoch 12 
2025-10-07 11:42:00.848570: Current learning rate: 0.00946 
2025-10-07 11:44:41.105185: train_loss -0.7843 
2025-10-07 11:44:41.105516: val_loss -0.755 
2025-10-07 11:44:41.105596: Pseudo dice [0.8277] 
2025-10-07 11:44:41.105696: Epoch time: 160.26 s 
2025-10-07 11:44:41.105771: Yayy! New best EMA pseudo Dice: 0.8174 
2025-10-07 11:44:42.861390:  
2025-10-07 11:44:42.861655: Epoch 13 
2025-10-07 11:44:42.861789: Current learning rate: 0.00941 
2025-10-07 11:47:23.118402: train_loss -0.7781 
2025-10-07 11:47:23.118796: val_loss -0.7774 
2025-10-07 11:47:23.118876: Pseudo dice [0.8465] 
2025-10-07 11:47:23.118971: Epoch time: 160.26 s 
2025-10-07 11:47:23.119062: Yayy! New best EMA pseudo Dice: 0.8203 
2025-10-07 11:47:24.981917:  
2025-10-07 11:47:24.982152: Epoch 14 
2025-10-07 11:47:24.982284: Current learning rate: 0.00937 
2025-10-07 11:50:04.978593: train_loss -0.7975 
2025-10-07 11:50:04.978953: val_loss -0.7684 
2025-10-07 11:50:04.979052: Pseudo dice [0.8369] 
2025-10-07 11:50:04.979145: Epoch time: 160.0 s 
2025-10-07 11:50:04.979209: Yayy! New best EMA pseudo Dice: 0.822 
2025-10-07 11:50:06.837617:  
2025-10-07 11:50:06.837872: Epoch 15 
2025-10-07 11:50:06.838034: Current learning rate: 0.00932 
2025-10-07 11:52:46.799937: train_loss -0.7884 
2025-10-07 11:52:46.800260: val_loss -0.7492 
2025-10-07 11:52:46.800334: Pseudo dice [0.8286] 
2025-10-07 11:52:46.800429: Epoch time: 159.96 s 
2025-10-07 11:52:46.800500: Yayy! New best EMA pseudo Dice: 0.8226 
2025-10-07 11:52:48.606287:  
2025-10-07 11:52:48.606482: Epoch 16 
2025-10-07 11:52:48.606602: Current learning rate: 0.00928 
2025-10-07 11:55:28.835530: train_loss -0.787 
2025-10-07 11:55:28.835966: val_loss -0.7641 
2025-10-07 11:55:28.836075: Pseudo dice [0.8315] 
2025-10-07 11:55:28.836180: Epoch time: 160.23 s 
2025-10-07 11:55:28.836253: Yayy! New best EMA pseudo Dice: 0.8235 
2025-10-07 11:55:30.771466:  
2025-10-07 11:55:30.771710: Epoch 17 
2025-10-07 11:55:30.771834: Current learning rate: 0.00923 
2025-10-07 11:58:11.224667: train_loss -0.7937 
2025-10-07 11:58:11.224998: val_loss -0.7671 
2025-10-07 11:58:11.225090: Pseudo dice [0.8363] 
2025-10-07 11:58:11.225181: Epoch time: 160.45 s 
2025-10-07 11:58:11.225257: Yayy! New best EMA pseudo Dice: 0.8248 
2025-10-07 11:58:13.113590:  
2025-10-07 11:58:13.113849: Epoch 18 
2025-10-07 11:58:13.113976: Current learning rate: 0.00919 
2025-10-07 12:00:53.396465: train_loss -0.796 
2025-10-07 12:00:53.396867: val_loss -0.7741 
2025-10-07 12:00:53.396951: Pseudo dice [0.8415] 
2025-10-07 12:00:53.397039: Epoch time: 160.28 s 
2025-10-07 12:00:53.397105: Yayy! New best EMA pseudo Dice: 0.8265 
2025-10-07 12:00:55.361758:  
2025-10-07 12:00:55.362121: Epoch 19 
2025-10-07 12:00:55.362342: Current learning rate: 0.00914 
2025-10-07 12:03:35.796340: train_loss -0.79 
2025-10-07 12:03:35.796729: val_loss -0.7585 
2025-10-07 12:03:35.796815: Pseudo dice [0.8322] 
2025-10-07 12:03:35.796919: Epoch time: 160.44 s 
2025-10-07 12:03:35.796997: Yayy! New best EMA pseudo Dice: 0.8271 
2025-10-07 12:03:37.723463:  
2025-10-07 12:03:37.723702: Epoch 20 
2025-10-07 12:03:37.723822: Current learning rate: 0.0091 
2025-10-07 12:06:17.796370: train_loss -0.8 
2025-10-07 12:06:17.796744: val_loss -0.741 
2025-10-07 12:06:17.796838: Pseudo dice [0.8172] 
2025-10-07 12:06:17.796925: Epoch time: 160.07 s 
2025-10-07 12:06:19.629090:  
2025-10-07 12:06:19.629318: Epoch 21 
2025-10-07 12:06:19.629451: Current learning rate: 0.00905 
2025-10-07 12:08:59.693661: train_loss -0.7946 
2025-10-07 12:08:59.694357: val_loss -0.7697 
2025-10-07 12:08:59.694438: Pseudo dice [0.8416] 
2025-10-07 12:08:59.694562: Epoch time: 160.07 s 
2025-10-07 12:08:59.694658: Yayy! New best EMA pseudo Dice: 0.8276 
2025-10-07 12:09:01.423732:  
2025-10-07 12:09:01.423951: Epoch 22 
2025-10-07 12:09:01.424070: Current learning rate: 0.009 
2025-10-07 12:11:41.635178: train_loss -0.79 
2025-10-07 12:11:41.635551: val_loss -0.7787 
2025-10-07 12:11:41.635661: Pseudo dice [0.8488] 
2025-10-07 12:11:41.635760: Epoch time: 160.21 s 
2025-10-07 12:11:41.635826: Yayy! New best EMA pseudo Dice: 0.8297 
2025-10-07 12:11:43.385831:  
2025-10-07 12:11:43.386112: Epoch 23 
2025-10-07 12:11:43.386239: Current learning rate: 0.00896 
2025-10-07 12:14:23.313778: train_loss -0.8055 
2025-10-07 12:14:23.314149: val_loss -0.766 
2025-10-07 12:14:23.314228: Pseudo dice [0.8382] 
2025-10-07 12:14:23.314314: Epoch time: 159.93 s 
2025-10-07 12:14:23.314378: Yayy! New best EMA pseudo Dice: 0.8306 
2025-10-07 12:14:25.077413:  
2025-10-07 12:14:25.077661: Epoch 24 
2025-10-07 12:14:25.077797: Current learning rate: 0.00891 
2025-10-07 12:17:05.146201: train_loss -0.8085 
2025-10-07 12:17:05.146662: val_loss -0.7715 
2025-10-07 12:17:05.146748: Pseudo dice [0.8425] 
2025-10-07 12:17:05.146839: Epoch time: 160.07 s 
2025-10-07 12:17:05.146903: Yayy! New best EMA pseudo Dice: 0.8318 
2025-10-07 12:17:06.976662:  
2025-10-07 12:17:06.976884: Epoch 25 
2025-10-07 12:17:06.977002: Current learning rate: 0.00887 
2025-10-07 12:19:47.090562: train_loss -0.8116 
2025-10-07 12:19:47.090941: val_loss -0.7479 
2025-10-07 12:19:47.091022: Pseudo dice [0.8263] 
2025-10-07 12:19:47.091111: Epoch time: 160.12 s 
2025-10-07 12:19:48.460632:  
2025-10-07 12:19:48.460856: Epoch 26 
2025-10-07 12:19:48.460984: Current learning rate: 0.00882 
2025-10-07 12:22:28.388121: train_loss -0.8113 
2025-10-07 12:22:28.388503: val_loss -0.7541 
2025-10-07 12:22:28.388597: Pseudo dice [0.8298] 
2025-10-07 12:22:28.388718: Epoch time: 159.93 s 
2025-10-07 12:22:29.763952:  
2025-10-07 12:22:29.764158: Epoch 27 
2025-10-07 12:22:29.764273: Current learning rate: 0.00878 
2025-10-07 12:25:09.882236: train_loss -0.8099 
2025-10-07 12:25:09.882684: val_loss -0.7656 
2025-10-07 12:25:09.882768: Pseudo dice [0.8358] 
2025-10-07 12:25:09.882861: Epoch time: 160.12 s 
2025-10-07 12:25:11.307820:  
2025-10-07 12:25:11.308012: Epoch 28 
2025-10-07 12:25:11.308130: Current learning rate: 0.00873 
2025-10-07 12:27:51.283148: train_loss -0.8103 
2025-10-07 12:27:51.283535: val_loss -0.7821 
2025-10-07 12:27:51.283621: Pseudo dice [0.8491] 
2025-10-07 12:27:51.283730: Epoch time: 159.98 s 
2025-10-07 12:27:51.283801: Yayy! New best EMA pseudo Dice: 0.8333 
2025-10-07 12:27:53.054394:  
2025-10-07 12:27:53.054589: Epoch 29 
2025-10-07 12:27:53.054729: Current learning rate: 0.00868 
2025-10-07 12:30:33.071265: train_loss -0.8075 
2025-10-07 12:30:33.071633: val_loss -0.7591 
2025-10-07 12:30:33.071729: Pseudo dice [0.8355] 
2025-10-07 12:30:33.071826: Epoch time: 160.02 s 
2025-10-07 12:30:33.071892: Yayy! New best EMA pseudo Dice: 0.8335 
2025-10-07 12:30:34.881966:  
2025-10-07 12:30:34.882260: Epoch 30 
2025-10-07 12:30:34.882384: Current learning rate: 0.00864 
2025-10-07 12:33:15.052817: train_loss -0.7938 
2025-10-07 12:33:15.053256: val_loss -0.7719 
2025-10-07 12:33:15.053342: Pseudo dice [0.8441] 
2025-10-07 12:33:15.053432: Epoch time: 160.17 s 
2025-10-07 12:33:15.053497: Yayy! New best EMA pseudo Dice: 0.8346 
2025-10-07 12:33:16.867993:  
2025-10-07 12:33:16.868183: Epoch 31 
2025-10-07 12:33:16.868301: Current learning rate: 0.00859 
2025-10-07 12:35:56.873137: train_loss -0.7933 
2025-10-07 12:35:56.873488: val_loss -0.7611 
2025-10-07 12:35:56.873567: Pseudo dice [0.8371] 
2025-10-07 12:35:56.873662: Epoch time: 160.01 s 
2025-10-07 12:35:56.873784: Yayy! New best EMA pseudo Dice: 0.8348 
2025-10-07 12:35:58.644028:  
2025-10-07 12:35:58.644246: Epoch 32 
2025-10-07 12:35:58.644371: Current learning rate: 0.00855 
2025-10-07 12:38:38.553592: train_loss -0.8095 
2025-10-07 12:38:38.553986: val_loss -0.7627 
2025-10-07 12:38:38.554081: Pseudo dice [0.8367] 
2025-10-07 12:38:38.554179: Epoch time: 159.91 s 
2025-10-07 12:38:38.554244: Yayy! New best EMA pseudo Dice: 0.835 
2025-10-07 12:38:40.755531:  
2025-10-07 12:38:40.755865: Epoch 33 
2025-10-07 12:38:40.755994: Current learning rate: 0.0085 
2025-10-07 12:41:20.526331: train_loss -0.8123 
2025-10-07 12:41:20.526704: val_loss -0.7711 
2025-10-07 12:41:20.526789: Pseudo dice [0.8421] 
2025-10-07 12:41:20.526883: Epoch time: 159.77 s 
2025-10-07 12:41:20.526952: Yayy! New best EMA pseudo Dice: 0.8357 
2025-10-07 12:41:22.402142:  
2025-10-07 12:41:22.402365: Epoch 34 
2025-10-07 12:41:22.402490: Current learning rate: 0.00846 
2025-10-07 12:44:02.243463: train_loss -0.8169 
2025-10-07 12:44:02.243826: val_loss -0.7785 
2025-10-07 12:44:02.243900: Pseudo dice [0.851] 
2025-10-07 12:44:02.243985: Epoch time: 159.84 s 
2025-10-07 12:44:02.244047: Yayy! New best EMA pseudo Dice: 0.8373 
2025-10-07 12:44:04.159116:  
2025-10-07 12:44:04.159321: Epoch 35 
2025-10-07 12:44:04.159436: Current learning rate: 0.00841 
2025-10-07 12:46:44.239764: train_loss -0.8195 
2025-10-07 12:46:44.240148: val_loss -0.7724 
2025-10-07 12:46:44.240233: Pseudo dice [0.8452] 
2025-10-07 12:46:44.240319: Epoch time: 160.08 s 
2025-10-07 12:46:44.240383: Yayy! New best EMA pseudo Dice: 0.838 
2025-10-07 12:46:46.150381:  
2025-10-07 12:46:46.150624: Epoch 36 
2025-10-07 12:46:46.150753: Current learning rate: 0.00836 
2025-10-07 12:49:26.177840: train_loss -0.8199 
2025-10-07 12:49:26.178178: val_loss -0.7728 
2025-10-07 12:49:26.178253: Pseudo dice [0.8462] 
2025-10-07 12:49:26.178336: Epoch time: 160.03 s 
2025-10-07 12:49:26.178415: Yayy! New best EMA pseudo Dice: 0.8389 
2025-10-07 12:49:28.000592:  
2025-10-07 12:49:28.000798: Epoch 37 
2025-10-07 12:49:28.000915: Current learning rate: 0.00832 
2025-10-07 12:52:07.839898: train_loss -0.8262 
2025-10-07 12:52:07.840254: val_loss -0.7714 
2025-10-07 12:52:07.840328: Pseudo dice [0.8425] 
2025-10-07 12:52:07.840412: Epoch time: 159.84 s 
2025-10-07 12:52:07.840476: Yayy! New best EMA pseudo Dice: 0.8392 
2025-10-07 12:52:09.695548:  
2025-10-07 12:52:09.695734: Epoch 38 
2025-10-07 12:52:09.695849: Current learning rate: 0.00827 
2025-10-07 12:54:49.571327: train_loss -0.8244 
2025-10-07 12:54:49.571672: val_loss -0.7798 
2025-10-07 12:54:49.571758: Pseudo dice [0.8509] 
2025-10-07 12:54:49.571851: Epoch time: 159.88 s 
2025-10-07 12:54:49.571916: Yayy! New best EMA pseudo Dice: 0.8404 
2025-10-07 12:54:51.409606:  
2025-10-07 12:54:51.409829: Epoch 39 
2025-10-07 12:54:51.409958: Current learning rate: 0.00823 
2025-10-07 12:57:31.041812: train_loss -0.8238 
2025-10-07 12:57:31.042150: val_loss -0.7609 
2025-10-07 12:57:31.042234: Pseudo dice [0.8359] 
2025-10-07 12:57:31.042325: Epoch time: 159.63 s 
2025-10-07 12:57:32.470683:  
2025-10-07 12:57:32.470877: Epoch 40 
2025-10-07 12:57:32.470994: Current learning rate: 0.00818 
2025-10-07 13:00:12.317014: train_loss -0.8243 
2025-10-07 13:00:12.317353: val_loss -0.7652 
2025-10-07 13:00:12.317430: Pseudo dice [0.8392] 
2025-10-07 13:00:12.317538: Epoch time: 159.85 s 
2025-10-07 13:00:13.779136:  
2025-10-07 13:00:13.779317: Epoch 41 
2025-10-07 13:00:13.779433: Current learning rate: 0.00813 
2025-10-07 13:02:53.871393: train_loss -0.8249 
2025-10-07 13:02:53.871742: val_loss -0.7704 
2025-10-07 13:02:53.871867: Pseudo dice [0.84] 
2025-10-07 13:02:53.871959: Epoch time: 160.09 s 
2025-10-07 13:02:55.187445:  
2025-10-07 13:02:55.187638: Epoch 42 
2025-10-07 13:02:55.187766: Current learning rate: 0.00809 
2025-10-07 13:05:34.963127: train_loss -0.8258 
2025-10-07 13:05:34.963513: val_loss -0.7658 
2025-10-07 13:05:34.963597: Pseudo dice [0.8406] 
2025-10-07 13:05:34.963696: Epoch time: 159.78 s 
2025-10-07 13:05:36.761714:  
2025-10-07 13:05:36.761950: Epoch 43 
2025-10-07 13:05:36.762065: Current learning rate: 0.00804 
2025-10-07 13:08:16.812582: train_loss -0.8299 
2025-10-07 13:08:16.812989: val_loss -0.7664 
2025-10-07 13:08:16.813075: Pseudo dice [0.8413] 
2025-10-07 13:08:16.813168: Epoch time: 160.05 s 
2025-10-07 13:08:18.212428:  
2025-10-07 13:08:18.212676: Epoch 44 
2025-10-07 13:08:18.212800: Current learning rate: 0.008 
2025-10-07 13:10:58.333885: train_loss -0.8336 
2025-10-07 13:10:58.334308: val_loss -0.7719 
2025-10-07 13:10:58.334392: Pseudo dice [0.844] 
2025-10-07 13:10:58.334481: Epoch time: 160.12 s 
2025-10-07 13:10:58.334550: Yayy! New best EMA pseudo Dice: 0.8405 
2025-10-07 13:11:00.159692:  
2025-10-07 13:11:00.159898: Epoch 45 
2025-10-07 13:11:00.160021: Current learning rate: 0.00795 
2025-10-07 13:13:40.298820: train_loss -0.8321 
2025-10-07 13:13:40.299214: val_loss -0.7575 
2025-10-07 13:13:40.299296: Pseudo dice [0.8287] 
2025-10-07 13:13:40.299391: Epoch time: 160.14 s 
2025-10-07 13:13:41.697064:  
2025-10-07 13:13:41.697301: Epoch 46 
2025-10-07 13:13:41.697455: Current learning rate: 0.0079 
2025-10-07 13:16:21.751382: train_loss -0.8353 
2025-10-07 13:16:21.751767: val_loss -0.7733 
2025-10-07 13:16:21.751849: Pseudo dice [0.842] 
2025-10-07 13:16:21.751940: Epoch time: 160.06 s 
2025-10-07 13:16:23.162503:  
2025-10-07 13:16:23.162832: Epoch 47 
2025-10-07 13:16:23.162958: Current learning rate: 0.00786 
2025-10-07 13:19:03.119172: train_loss -0.8391 
2025-10-07 13:19:03.119645: val_loss -0.7694 
2025-10-07 13:19:03.119749: Pseudo dice [0.844] 
2025-10-07 13:19:03.119902: Epoch time: 159.96 s 
2025-10-07 13:19:04.581031:  
2025-10-07 13:19:04.581294: Epoch 48 
2025-10-07 13:19:04.581431: Current learning rate: 0.00781 
2025-10-07 13:21:44.602932: train_loss -0.8357 
2025-10-07 13:21:44.603291: val_loss -0.7702 
2025-10-07 13:21:44.603379: Pseudo dice [0.8443] 
2025-10-07 13:21:44.603527: Epoch time: 160.02 s 
2025-10-07 13:21:46.028206:  
2025-10-07 13:21:46.028605: Epoch 49 
2025-10-07 13:21:46.028744: Current learning rate: 0.00777 
2025-10-07 13:24:26.041323: train_loss -0.8332 
2025-10-07 13:24:26.041738: val_loss -0.7689 
2025-10-07 13:24:26.041829: Pseudo dice [0.8407] 
2025-10-07 13:24:26.041986: Epoch time: 160.01 s 
2025-10-07 13:24:27.814009:  
2025-10-07 13:24:27.814245: Epoch 50 
2025-10-07 13:24:27.814372: Current learning rate: 0.00772 
2025-10-07 13:27:07.810399: train_loss -0.8406 
2025-10-07 13:27:07.810778: val_loss -0.7601 
2025-10-07 13:27:07.810863: Pseudo dice [0.8358] 
2025-10-07 13:27:07.810951: Epoch time: 160.0 s 
2025-10-07 13:27:09.256039:  
2025-10-07 13:27:09.256228: Epoch 51 
2025-10-07 13:27:09.256387: Current learning rate: 0.00767 
2025-10-07 13:29:49.395739: train_loss -0.8393 
2025-10-07 13:29:49.396128: val_loss -0.7587 
2025-10-07 13:29:49.396212: Pseudo dice [0.8337] 
2025-10-07 13:29:49.396304: Epoch time: 160.14 s 
2025-10-07 13:29:50.841782:  
2025-10-07 13:29:50.842000: Epoch 52 
2025-10-07 13:29:50.842133: Current learning rate: 0.00763 
2025-10-07 13:32:30.871149: train_loss -0.8393 
2025-10-07 13:32:30.871523: val_loss -0.7757 
2025-10-07 13:32:30.871614: Pseudo dice [0.8476] 
2025-10-07 13:32:30.871730: Epoch time: 160.03 s 
2025-10-07 13:32:32.332500:  
2025-10-07 13:32:32.332743: Epoch 53 
2025-10-07 13:32:32.332875: Current learning rate: 0.00758 
2025-10-07 13:35:12.236882: train_loss -0.8472 
2025-10-07 13:35:12.237262: val_loss -0.7692 
2025-10-07 13:35:12.237348: Pseudo dice [0.8424] 
2025-10-07 13:35:12.237439: Epoch time: 159.91 s 
2025-10-07 13:35:13.696431:  
2025-10-07 13:35:13.696661: Epoch 54 
2025-10-07 13:35:13.696784: Current learning rate: 0.00753 
2025-10-07 13:37:53.557486: train_loss -0.8401 
2025-10-07 13:37:53.557866: val_loss -0.7574 
2025-10-07 13:37:53.557962: Pseudo dice [0.8343] 
2025-10-07 13:37:53.558059: Epoch time: 159.86 s 
2025-10-07 13:37:55.486936:  
2025-10-07 13:37:55.487138: Epoch 55 
2025-10-07 13:37:55.487263: Current learning rate: 0.00749 
2025-10-07 13:40:35.598247: train_loss -0.8394 
2025-10-07 13:40:35.598625: val_loss -0.7701 
2025-10-07 13:40:35.598734: Pseudo dice [0.8432] 
2025-10-07 13:40:35.598826: Epoch time: 160.11 s 
2025-10-07 13:40:37.060307:  
2025-10-07 13:40:37.060547: Epoch 56 
2025-10-07 13:40:37.060752: Current learning rate: 0.00744 
2025-10-07 13:43:16.937782: train_loss -0.8441 
2025-10-07 13:43:16.938167: val_loss -0.7759 
2025-10-07 13:43:16.938250: Pseudo dice [0.8468] 
2025-10-07 13:43:16.938340: Epoch time: 159.88 s 
2025-10-07 13:43:16.938410: Yayy! New best EMA pseudo Dice: 0.8408 
2025-10-07 13:43:18.794011:  
2025-10-07 13:43:18.794299: Epoch 57 
2025-10-07 13:43:18.794488: Current learning rate: 0.00739 
2025-10-07 13:45:58.791141: train_loss -0.8423 
2025-10-07 13:45:58.791498: val_loss -0.7768 
2025-10-07 13:45:58.791581: Pseudo dice [0.8471] 
2025-10-07 13:45:58.791686: Epoch time: 160.0 s 
2025-10-07 13:45:58.791758: Yayy! New best EMA pseudo Dice: 0.8414 
2025-10-07 13:46:00.690897:  
2025-10-07 13:46:00.691101: Epoch 58 
2025-10-07 13:46:00.691218: Current learning rate: 0.00735 
2025-10-07 13:48:40.884134: train_loss -0.8462 
2025-10-07 13:48:40.884466: val_loss -0.7597 
2025-10-07 13:48:40.884548: Pseudo dice [0.8355] 
2025-10-07 13:48:40.884639: Epoch time: 160.19 s 
2025-10-07 13:48:42.378643:  
2025-10-07 13:48:42.378840: Epoch 59 
2025-10-07 13:48:42.378997: Current learning rate: 0.0073 
2025-10-07 13:51:22.427598: train_loss -0.8443 
2025-10-07 13:51:22.427940: val_loss -0.7643 
2025-10-07 13:51:22.428070: Pseudo dice [0.8376] 
2025-10-07 13:51:22.428166: Epoch time: 160.05 s 
2025-10-07 13:51:23.952835:  
2025-10-07 13:51:23.953072: Epoch 60 
2025-10-07 13:51:23.953201: Current learning rate: 0.00725 
2025-10-07 13:54:04.013045: train_loss -0.8456 
2025-10-07 13:54:04.013375: val_loss -0.7614 
2025-10-07 13:54:04.013508: Pseudo dice [0.8398] 
2025-10-07 13:54:04.013702: Epoch time: 160.06 s 
2025-10-07 13:54:05.608663:  
2025-10-07 13:54:05.608956: Epoch 61 
2025-10-07 13:54:05.609085: Current learning rate: 0.00721 
2025-10-07 13:56:45.687408: train_loss -0.8523 
2025-10-07 13:56:45.687732: val_loss -0.7689 
2025-10-07 13:56:45.687842: Pseudo dice [0.8446] 
2025-10-07 13:56:45.687943: Epoch time: 160.08 s 
2025-10-07 13:56:47.215275:  
2025-10-07 13:56:47.215512: Epoch 62 
2025-10-07 13:56:47.215673: Current learning rate: 0.00716 
2025-10-07 13:59:27.397747: train_loss -0.8455 
2025-10-07 13:59:27.398125: val_loss -0.7673 
2025-10-07 13:59:27.398209: Pseudo dice [0.8456] 
2025-10-07 13:59:27.398328: Epoch time: 160.18 s 
2025-10-07 13:59:28.975120:  
2025-10-07 13:59:28.975345: Epoch 63 
2025-10-07 13:59:28.975492: Current learning rate: 0.00711 
2025-10-07 14:02:09.143756: train_loss -0.8565 
2025-10-07 14:02:09.144123: val_loss -0.7705 
2025-10-07 14:02:09.144214: Pseudo dice [0.8433] 
2025-10-07 14:02:09.144307: Epoch time: 160.17 s 
2025-10-07 14:02:09.144377: Yayy! New best EMA pseudo Dice: 0.8415 
2025-10-07 14:02:11.088064:  
2025-10-07 14:02:11.088284: Epoch 64 
2025-10-07 14:02:11.088414: Current learning rate: 0.00707 
2025-10-07 14:04:51.238589: train_loss -0.8539 
2025-10-07 14:04:51.238958: val_loss -0.7607 
2025-10-07 14:04:51.239045: Pseudo dice [0.836] 
2025-10-07 14:04:51.239140: Epoch time: 160.15 s 
2025-10-07 14:04:52.772042:  
2025-10-07 14:04:52.772271: Epoch 65 
2025-10-07 14:04:52.772393: Current learning rate: 0.00702 
2025-10-07 14:07:32.968727: train_loss -0.8527 
2025-10-07 14:07:32.969089: val_loss -0.7622 
2025-10-07 14:07:32.969172: Pseudo dice [0.838] 
2025-10-07 14:07:32.969308: Epoch time: 160.2 s 
2025-10-07 14:07:34.933070:  
2025-10-07 14:07:34.933297: Epoch 66 
2025-10-07 14:07:34.933447: Current learning rate: 0.00697 
2025-10-07 14:10:15.131338: train_loss -0.8551 
2025-10-07 14:10:15.131717: val_loss -0.7677 
2025-10-07 14:10:15.131809: Pseudo dice [0.8411] 
2025-10-07 14:10:15.131906: Epoch time: 160.2 s 
2025-10-07 14:10:16.687866:  
2025-10-07 14:10:16.688063: Epoch 67 
2025-10-07 14:10:16.688187: Current learning rate: 0.00693 
2025-10-07 14:12:56.696138: train_loss -0.8562 
2025-10-07 14:12:56.696439: val_loss -0.7617 
2025-10-07 14:12:56.696522: Pseudo dice [0.8372] 
2025-10-07 14:12:56.696619: Epoch time: 160.01 s 
2025-10-07 14:12:58.280759:  
2025-10-07 14:12:58.280993: Epoch 68 
2025-10-07 14:12:58.281133: Current learning rate: 0.00688 
2025-10-07 14:15:38.125945: train_loss -0.8592 
2025-10-07 14:15:38.126302: val_loss -0.7501 
2025-10-07 14:15:38.126384: Pseudo dice [0.8321] 
2025-10-07 14:15:38.126482: Epoch time: 159.85 s 
2025-10-07 14:15:39.578860:  
2025-10-07 14:15:39.579083: Epoch 69 
2025-10-07 14:15:39.579200: Current learning rate: 0.00683 
2025-10-07 14:18:19.454637: train_loss -0.8577 
2025-10-07 14:18:19.455281: val_loss -0.7729 
2025-10-07 14:18:19.455374: Pseudo dice [0.8489] 
2025-10-07 14:18:19.455470: Epoch time: 159.88 s 
2025-10-07 14:18:20.870704:  
2025-10-07 14:18:20.870921: Epoch 70 
2025-10-07 14:18:20.871037: Current learning rate: 0.00679 
2025-10-07 14:21:00.655188: train_loss -0.8585 
2025-10-07 14:21:00.655529: val_loss -0.7669 
2025-10-07 14:21:00.655605: Pseudo dice [0.8404] 
2025-10-07 14:21:00.655718: Epoch time: 159.79 s 
2025-10-07 14:21:02.069935:  
2025-10-07 14:21:02.070148: Epoch 71 
2025-10-07 14:21:02.070269: Current learning rate: 0.00674 
2025-10-07 14:23:41.626256: train_loss -0.8588 
2025-10-07 14:23:41.626585: val_loss -0.7663 
2025-10-07 14:23:41.626681: Pseudo dice [0.8418] 
2025-10-07 14:23:41.626772: Epoch time: 159.56 s 
2025-10-07 14:23:43.002917:  
2025-10-07 14:23:43.003123: Epoch 72 
2025-10-07 14:23:43.003238: Current learning rate: 0.00669 
2025-10-07 14:26:22.617330: train_loss -0.8621 
2025-10-07 14:26:22.617694: val_loss -0.7656 
2025-10-07 14:26:22.617776: Pseudo dice [0.8436] 
2025-10-07 14:26:22.617862: Epoch time: 159.62 s 
2025-10-07 14:26:24.042466:  
2025-10-07 14:26:24.042715: Epoch 73 
2025-10-07 14:26:24.042841: Current learning rate: 0.00665 
2025-10-07 14:29:03.696345: train_loss -0.8579 
2025-10-07 14:29:03.696656: val_loss -0.7735 
2025-10-07 14:29:03.696734: Pseudo dice [0.8466] 
2025-10-07 14:29:03.696820: Epoch time: 159.66 s 
2025-10-07 14:29:05.086788:  
2025-10-07 14:29:05.086992: Epoch 74 
2025-10-07 14:29:05.087109: Current learning rate: 0.0066 
2025-10-07 14:31:44.522364: train_loss -0.862 
2025-10-07 14:31:44.522720: val_loss -0.7732 
2025-10-07 14:31:44.522800: Pseudo dice [0.847] 
2025-10-07 14:31:44.522882: Epoch time: 159.44 s 
2025-10-07 14:31:44.522941: Yayy! New best EMA pseudo Dice: 0.842 
2025-10-07 14:31:46.246330:  
2025-10-07 14:31:46.246596: Epoch 75 
2025-10-07 14:31:46.246748: Current learning rate: 0.00655 
2025-10-07 14:34:25.927353: train_loss -0.8605 
2025-10-07 14:34:25.927713: val_loss -0.7637 
2025-10-07 14:34:25.927811: Pseudo dice [0.8395] 
2025-10-07 14:34:25.927926: Epoch time: 159.68 s 
2025-10-07 14:34:27.433610:  
2025-10-07 14:34:27.433835: Epoch 76 
2025-10-07 14:34:27.433955: Current learning rate: 0.0065 
2025-10-07 14:37:07.388444: train_loss -0.8595 
2025-10-07 14:37:07.388819: val_loss -0.7713 
2025-10-07 14:37:07.388904: Pseudo dice [0.8453] 
2025-10-07 14:37:07.388996: Epoch time: 159.96 s 
2025-10-07 14:37:07.389065: Yayy! New best EMA pseudo Dice: 0.8421 
2025-10-07 14:37:09.637340:  
2025-10-07 14:37:09.637575: Epoch 77 
2025-10-07 14:37:09.637744: Current learning rate: 0.00646 
2025-10-07 14:39:49.431493: train_loss -0.8621 
2025-10-07 14:39:49.431885: val_loss -0.7772 
2025-10-07 14:39:49.431995: Pseudo dice [0.8518] 
2025-10-07 14:39:49.432085: Epoch time: 159.8 s 
2025-10-07 14:39:49.432151: Yayy! New best EMA pseudo Dice: 0.8431 
2025-10-07 14:39:51.474856:  
2025-10-07 14:39:51.475094: Epoch 78 
2025-10-07 14:39:51.475211: Current learning rate: 0.00641 
2025-10-07 14:42:31.496912: train_loss -0.8653 
2025-10-07 14:42:31.497258: val_loss -0.7447 
2025-10-07 14:42:31.497361: Pseudo dice [0.8262] 
2025-10-07 14:42:31.497489: Epoch time: 160.02 s 
2025-10-07 14:42:32.992908:  
2025-10-07 14:42:32.993152: Epoch 79 
2025-10-07 14:42:32.993277: Current learning rate: 0.00636 
2025-10-07 14:45:12.815901: train_loss -0.8637 
2025-10-07 14:45:12.816292: val_loss -0.7749 
2025-10-07 14:45:12.816377: Pseudo dice [0.8467] 
2025-10-07 14:45:12.816468: Epoch time: 159.82 s 
2025-10-07 14:45:14.280093:  
2025-10-07 14:45:14.280361: Epoch 80 
2025-10-07 14:45:14.280496: Current learning rate: 0.00631 
2025-10-07 14:47:53.958350: train_loss -0.8634 
2025-10-07 14:47:53.958721: val_loss -0.7647 
2025-10-07 14:47:53.958803: Pseudo dice [0.8447] 
2025-10-07 14:47:53.958892: Epoch time: 159.68 s 
2025-10-07 14:47:55.437023:  
2025-10-07 14:47:55.437268: Epoch 81 
2025-10-07 14:47:55.437393: Current learning rate: 0.00627 
2025-10-07 14:50:35.239788: train_loss -0.8612 
2025-10-07 14:50:35.240137: val_loss -0.7755 
2025-10-07 14:50:35.240210: Pseudo dice [0.8456] 
2025-10-07 14:50:35.240295: Epoch time: 159.8 s 
2025-10-07 14:50:36.675618:  
2025-10-07 14:50:36.675923: Epoch 82 
2025-10-07 14:50:36.676045: Current learning rate: 0.00622 
2025-10-07 14:53:16.382762: train_loss -0.8617 
2025-10-07 14:53:16.383124: val_loss -0.7598 
2025-10-07 14:53:16.383202: Pseudo dice [0.8403] 
2025-10-07 14:53:16.383284: Epoch time: 159.71 s 
2025-10-07 14:53:17.655051:  
2025-10-07 14:53:17.655279: Epoch 83 
2025-10-07 14:53:17.655398: Current learning rate: 0.00617 
2025-10-07 14:55:57.259557: train_loss -0.8611 
2025-10-07 14:55:57.259931: val_loss -0.7763 
2025-10-07 14:55:57.260009: Pseudo dice [0.8488] 
2025-10-07 14:55:57.260105: Epoch time: 159.61 s 
2025-10-07 14:55:58.565072:  
2025-10-07 14:55:58.565290: Epoch 84 
2025-10-07 14:55:58.565422: Current learning rate: 0.00612 
2025-10-07 14:58:38.404052: train_loss -0.8632 
2025-10-07 14:58:38.404417: val_loss -0.7779 
2025-10-07 14:58:38.404487: Pseudo dice [0.8481] 
2025-10-07 14:58:38.404567: Epoch time: 159.84 s 
2025-10-07 14:58:38.404626: Yayy! New best EMA pseudo Dice: 0.8435 
2025-10-07 14:58:40.140549:  
2025-10-07 14:58:40.140746: Epoch 85 
2025-10-07 14:58:40.140860: Current learning rate: 0.00608 
2025-10-07 15:01:19.955923: train_loss -0.8682 
2025-10-07 15:01:19.956271: val_loss -0.7744 
2025-10-07 15:01:19.956348: Pseudo dice [0.847] 
2025-10-07 15:01:19.956503: Epoch time: 159.82 s 
2025-10-07 15:01:19.956618: Yayy! New best EMA pseudo Dice: 0.8438 
2025-10-07 15:01:21.719366:  
2025-10-07 15:01:21.719566: Epoch 86 
2025-10-07 15:01:21.719697: Current learning rate: 0.00603 
2025-10-07 15:04:01.481398: train_loss -0.8668 
2025-10-07 15:04:01.481776: val_loss -0.7614 
2025-10-07 15:04:01.481855: Pseudo dice [0.839] 
2025-10-07 15:04:01.481944: Epoch time: 159.76 s 
2025-10-07 15:04:02.810782:  
2025-10-07 15:04:02.810952: Epoch 87 
2025-10-07 15:04:02.811078: Current learning rate: 0.00598 
2025-10-07 15:06:42.737881: train_loss -0.8671 
2025-10-07 15:06:42.738262: val_loss -0.7612 
2025-10-07 15:06:42.738342: Pseudo dice [0.8399] 
2025-10-07 15:06:42.738434: Epoch time: 159.93 s 
2025-10-07 15:06:44.442734:  
2025-10-07 15:06:44.442954: Epoch 88 
2025-10-07 15:06:44.443081: Current learning rate: 0.00593 
2025-10-07 15:09:24.711670: train_loss -0.8713 
2025-10-07 15:09:24.711990: val_loss -0.768 
2025-10-07 15:09:24.712129: Pseudo dice [0.845] 
2025-10-07 15:09:24.712245: Epoch time: 160.27 s 
2025-10-07 15:09:26.208259:  
2025-10-07 15:09:26.208503: Epoch 89 
2025-10-07 15:09:26.208631: Current learning rate: 0.00589 
2025-10-07 15:12:07.046969: train_loss -0.8714 
2025-10-07 15:12:07.047354: val_loss -0.7783 
2025-10-07 15:12:07.047436: Pseudo dice [0.8524] 
2025-10-07 15:12:07.047530: Epoch time: 160.84 s 
2025-10-07 15:12:07.047600: Yayy! New best EMA pseudo Dice: 0.8441 
2025-10-07 15:12:08.929248:  
2025-10-07 15:12:08.929510: Epoch 90 
2025-10-07 15:12:08.929672: Current learning rate: 0.00584 
2025-10-07 15:14:49.320092: train_loss -0.8724 
2025-10-07 15:14:49.320432: val_loss -0.7698 
2025-10-07 15:14:49.320515: Pseudo dice [0.8488] 
2025-10-07 15:14:49.320609: Epoch time: 160.39 s 
2025-10-07 15:14:49.320692: Yayy! New best EMA pseudo Dice: 0.8446 
2025-10-07 15:14:51.214066:  
2025-10-07 15:14:51.214299: Epoch 91 
2025-10-07 15:14:51.214424: Current learning rate: 0.00579 
2025-10-07 15:17:31.445162: train_loss -0.8747 
2025-10-07 15:17:31.445526: val_loss -0.7621 
2025-10-07 15:17:31.445611: Pseudo dice [0.8395] 
2025-10-07 15:17:31.445729: Epoch time: 160.23 s 
2025-10-07 15:17:32.872644:  
2025-10-07 15:17:32.872886: Epoch 92 
2025-10-07 15:17:32.873069: Current learning rate: 0.00574 
2025-10-07 15:20:12.756426: train_loss -0.8713 
2025-10-07 15:20:12.756821: val_loss -0.7733 
2025-10-07 15:20:12.756932: Pseudo dice [0.8496] 
2025-10-07 15:20:12.757028: Epoch time: 159.89 s 
2025-10-07 15:20:12.757092: Yayy! New best EMA pseudo Dice: 0.8446 
2025-10-07 15:20:14.472950:  
2025-10-07 15:20:14.473145: Epoch 93 
2025-10-07 15:20:14.473258: Current learning rate: 0.0057 
2025-10-07 15:22:54.377605: train_loss -0.8674 
2025-10-07 15:22:54.377990: val_loss -0.7702 
2025-10-07 15:22:54.378072: Pseudo dice [0.8443] 
2025-10-07 15:22:54.378412: Epoch time: 159.91 s 
2025-10-07 15:22:55.786278:  
2025-10-07 15:22:55.786548: Epoch 94 
2025-10-07 15:22:55.786713: Current learning rate: 0.00565 
2025-10-07 15:25:35.773420: train_loss -0.87 
2025-10-07 15:25:35.773796: val_loss -0.754 
2025-10-07 15:25:35.773877: Pseudo dice [0.8323] 
2025-10-07 15:25:35.773968: Epoch time: 159.99 s 
2025-10-07 15:25:37.122425:  
2025-10-07 15:25:37.122638: Epoch 95 
2025-10-07 15:25:37.122799: Current learning rate: 0.0056 
2025-10-07 15:28:17.057285: train_loss -0.8701 
2025-10-07 15:28:17.057693: val_loss -0.7521 
2025-10-07 15:28:17.057786: Pseudo dice [0.8355] 
2025-10-07 15:28:17.057940: Epoch time: 159.94 s 
2025-10-07 15:28:18.419908:  
2025-10-07 15:28:18.420132: Epoch 96 
2025-10-07 15:28:18.420249: Current learning rate: 0.00555 
2025-10-07 15:30:58.667007: train_loss -0.8706 
2025-10-07 15:30:58.667361: val_loss -0.7605 
2025-10-07 15:30:58.667443: Pseudo dice [0.8412] 
2025-10-07 15:30:58.667539: Epoch time: 160.25 s 
2025-10-07 15:31:00.053836:  
2025-10-07 15:31:00.054088: Epoch 97 
2025-10-07 15:31:00.054225: Current learning rate: 0.0055 
2025-10-07 15:33:40.202776: train_loss -0.8774 
2025-10-07 15:33:40.203116: val_loss -0.7664 
2025-10-07 15:33:40.203190: Pseudo dice [0.843] 
2025-10-07 15:33:40.203277: Epoch time: 160.15 s 
2025-10-07 15:33:41.635273:  
2025-10-07 15:33:41.635479: Epoch 98 
2025-10-07 15:33:41.635602: Current learning rate: 0.00546 
2025-10-07 15:36:21.658297: train_loss -0.8725 
2025-10-07 15:36:21.658660: val_loss -0.7673 
2025-10-07 15:36:21.658747: Pseudo dice [0.8484] 
2025-10-07 15:36:21.658834: Epoch time: 160.02 s 
2025-10-07 15:36:23.080459:  
2025-10-07 15:36:23.080710: Epoch 99 
2025-10-07 15:36:23.080845: Current learning rate: 0.00541 
2025-10-07 15:39:03.013817: train_loss -0.8766 
2025-10-07 15:39:03.014179: val_loss -0.7649 
2025-10-07 15:39:03.014270: Pseudo dice [0.8429] 
2025-10-07 15:39:03.014360: Epoch time: 159.93 s 
2025-10-07 15:39:05.135604:  
2025-10-07 15:39:05.135852: Epoch 100 
2025-10-07 15:39:05.135975: Current learning rate: 0.00536 
2025-10-07 15:41:45.020396: train_loss -0.8752 
2025-10-07 15:41:45.020768: val_loss -0.7685 
2025-10-07 15:41:45.020871: Pseudo dice [0.8443] 
2025-10-07 15:41:45.021000: Epoch time: 159.89 s 
2025-10-07 15:41:46.378886:  
2025-10-07 15:41:46.379102: Epoch 101 
2025-10-07 15:41:46.379223: Current learning rate: 0.00531 
2025-10-07 15:44:26.111920: train_loss -0.8727 
2025-10-07 15:44:26.112496: val_loss -0.7543 
2025-10-07 15:44:26.112615: Pseudo dice [0.8326] 
2025-10-07 15:44:26.112742: Epoch time: 159.73 s 
2025-10-07 15:44:27.468379:  
2025-10-07 15:44:27.468605: Epoch 102 
2025-10-07 15:44:27.468736: Current learning rate: 0.00526 
2025-10-07 15:47:07.292428: train_loss -0.8784 
2025-10-07 15:47:07.292795: val_loss -0.7744 
2025-10-07 15:47:07.292876: Pseudo dice [0.8492] 
2025-10-07 15:47:07.292967: Epoch time: 159.83 s 
2025-10-07 15:47:08.655510:  
2025-10-07 15:47:08.655758: Epoch 103 
2025-10-07 15:47:08.655887: Current learning rate: 0.00521 
2025-10-07 15:49:48.489234: train_loss -0.875 
2025-10-07 15:49:48.489642: val_loss -0.7741 
2025-10-07 15:49:48.489739: Pseudo dice [0.8496] 
2025-10-07 15:49:48.489830: Epoch time: 159.84 s 
2025-10-07 15:49:49.858055:  
2025-10-07 15:49:49.858261: Epoch 104 
2025-10-07 15:49:49.858378: Current learning rate: 0.00517 
2025-10-07 15:52:29.719132: train_loss -0.8764 
2025-10-07 15:52:29.719501: val_loss -0.7708 
2025-10-07 15:52:29.719582: Pseudo dice [0.8496] 
2025-10-07 15:52:29.719680: Epoch time: 159.86 s 
2025-10-07 15:52:31.111626:  
2025-10-07 15:52:31.111916: Epoch 105 
2025-10-07 15:52:31.112055: Current learning rate: 0.00512 
2025-10-07 15:55:11.199867: train_loss -0.8794 
2025-10-07 15:55:11.200214: val_loss -0.7787 
2025-10-07 15:55:11.200289: Pseudo dice [0.853] 
2025-10-07 15:55:11.200374: Epoch time: 160.09 s 
2025-10-07 15:55:11.200437: Yayy! New best EMA pseudo Dice: 0.845 
2025-10-07 15:55:12.954017:  
2025-10-07 15:55:12.954230: Epoch 106 
2025-10-07 15:55:12.954359: Current learning rate: 0.00507 
2025-10-07 15:57:52.796048: train_loss -0.8746 
2025-10-07 15:57:52.796373: val_loss -0.768 
2025-10-07 15:57:52.796465: Pseudo dice [0.8489] 
2025-10-07 15:57:52.796559: Epoch time: 159.84 s 
2025-10-07 15:57:52.796625: Yayy! New best EMA pseudo Dice: 0.8454 
2025-10-07 15:57:54.582230:  
2025-10-07 15:57:54.582442: Epoch 107 
2025-10-07 15:57:54.582579: Current learning rate: 0.00502 
2025-10-07 16:00:34.416454: train_loss -0.8796 
2025-10-07 16:00:34.416810: val_loss -0.7707 
2025-10-07 16:00:34.416904: Pseudo dice [0.8504] 
2025-10-07 16:00:34.417002: Epoch time: 159.84 s 
2025-10-07 16:00:34.417064: Yayy! New best EMA pseudo Dice: 0.8459 
2025-10-07 16:00:36.197932:  
2025-10-07 16:00:36.198181: Epoch 108 
2025-10-07 16:00:36.198304: Current learning rate: 0.00497 
2025-10-07 16:03:15.822294: train_loss -0.8793 
2025-10-07 16:03:15.822707: val_loss -0.7639 
2025-10-07 16:03:15.822795: Pseudo dice [0.8441] 
2025-10-07 16:03:15.822885: Epoch time: 159.63 s 
2025-10-07 16:03:17.165024:  
2025-10-07 16:03:17.165217: Epoch 109 
2025-10-07 16:03:17.165344: Current learning rate: 0.00492 
2025-10-07 16:05:56.893673: train_loss -0.8822 
2025-10-07 16:05:56.894027: val_loss -0.7597 
2025-10-07 16:05:56.894108: Pseudo dice [0.8408] 
2025-10-07 16:05:56.894201: Epoch time: 159.73 s 
2025-10-07 16:05:58.251578:  
2025-10-07 16:05:58.251771: Epoch 110 
2025-10-07 16:05:58.251904: Current learning rate: 0.00487 
2025-10-07 16:08:38.031753: train_loss -0.8787 
2025-10-07 16:08:38.032090: val_loss -0.7708 
2025-10-07 16:08:38.032167: Pseudo dice [0.8506] 
2025-10-07 16:08:38.032257: Epoch time: 159.78 s 
2025-10-07 16:08:39.751186:  
2025-10-07 16:08:39.751385: Epoch 111 
2025-10-07 16:08:39.751511: Current learning rate: 0.00483 
2025-10-07 16:11:19.662368: train_loss -0.8831 
2025-10-07 16:11:19.662704: val_loss -0.7692 
2025-10-07 16:11:19.662794: Pseudo dice [0.8482] 
2025-10-07 16:11:19.662880: Epoch time: 159.91 s 
2025-10-07 16:11:19.662945: Yayy! New best EMA pseudo Dice: 0.846 
2025-10-07 16:11:21.440360:  
2025-10-07 16:11:21.440565: Epoch 112 
2025-10-07 16:11:21.440694: Current learning rate: 0.00478 
2025-10-07 16:14:01.386609: train_loss -0.8839 
2025-10-07 16:14:01.386964: val_loss -0.7639 
2025-10-07 16:14:01.387053: Pseudo dice [0.8451] 
2025-10-07 16:14:01.387148: Epoch time: 159.95 s 
2025-10-07 16:14:02.749804:  
2025-10-07 16:14:02.750007: Epoch 113 
2025-10-07 16:14:02.750122: Current learning rate: 0.00473 
2025-10-07 16:16:42.452286: train_loss -0.881 
2025-10-07 16:16:42.452645: val_loss -0.7635 
2025-10-07 16:16:42.452734: Pseudo dice [0.8448] 
2025-10-07 16:16:42.452835: Epoch time: 159.7 s 
2025-10-07 16:16:43.790461:  
2025-10-07 16:16:43.790686: Epoch 114 
2025-10-07 16:16:43.790807: Current learning rate: 0.00468 
2025-10-07 16:19:23.591598: train_loss -0.8837 
2025-10-07 16:19:23.591960: val_loss -0.7597 
2025-10-07 16:19:23.592031: Pseudo dice [0.8389] 
2025-10-07 16:19:23.592115: Epoch time: 159.8 s 
2025-10-07 16:19:24.980958:  
2025-10-07 16:19:24.981166: Epoch 115 
2025-10-07 16:19:24.981279: Current learning rate: 0.00463 
2025-10-07 16:22:04.977281: train_loss -0.8834 
2025-10-07 16:22:04.977620: val_loss -0.7635 
2025-10-07 16:22:04.977708: Pseudo dice [0.8445] 
2025-10-07 16:22:04.977792: Epoch time: 160.0 s 
2025-10-07 16:22:06.356735:  
2025-10-07 16:22:06.356959: Epoch 116 
2025-10-07 16:22:06.357133: Current learning rate: 0.00458 
2025-10-07 16:24:46.218039: train_loss -0.883 
2025-10-07 16:24:46.218349: val_loss -0.7737 
2025-10-07 16:24:46.218438: Pseudo dice [0.8514] 
2025-10-07 16:24:46.218528: Epoch time: 159.86 s 
2025-10-07 16:24:47.611064:  
2025-10-07 16:24:47.611258: Epoch 117 
2025-10-07 16:24:47.611372: Current learning rate: 0.00453 
2025-10-07 16:27:27.455044: train_loss -0.884 
2025-10-07 16:27:27.455404: val_loss -0.7556 
2025-10-07 16:27:27.455482: Pseudo dice [0.8401] 
2025-10-07 16:27:27.455568: Epoch time: 159.85 s 
2025-10-07 16:27:28.849180:  
2025-10-07 16:27:28.849381: Epoch 118 
2025-10-07 16:27:28.849504: Current learning rate: 0.00448 
2025-10-07 16:30:08.743194: train_loss -0.883 
2025-10-07 16:30:08.743535: val_loss -0.7489 
2025-10-07 16:30:08.743618: Pseudo dice [0.8348] 
2025-10-07 16:30:08.766894: Epoch time: 159.9 s 
2025-10-07 16:30:10.164618:  
2025-10-07 16:30:10.164840: Epoch 119 
2025-10-07 16:30:10.164973: Current learning rate: 0.00443 
2025-10-07 16:32:49.872348: train_loss -0.8879 
2025-10-07 16:32:49.872693: val_loss -0.7499 
2025-10-07 16:32:49.872771: Pseudo dice [0.8364] 
2025-10-07 16:32:49.872859: Epoch time: 159.71 s 
2025-10-07 16:32:51.251345:  
2025-10-07 16:32:51.251540: Epoch 120 
2025-10-07 16:32:51.251663: Current learning rate: 0.00438 
2025-10-07 16:35:31.001375: train_loss -0.8854 
2025-10-07 16:35:31.001753: val_loss -0.7548 
2025-10-07 16:35:31.001848: Pseudo dice [0.8361] 
2025-10-07 16:35:31.001936: Epoch time: 159.75 s 
2025-10-07 16:35:32.385638:  
2025-10-07 16:35:32.385845: Epoch 121 
2025-10-07 16:35:32.385962: Current learning rate: 0.00433 
2025-10-07 16:38:12.050703: train_loss -0.8828 
2025-10-07 16:38:12.051072: val_loss -0.7662 
2025-10-07 16:38:12.051151: Pseudo dice [0.8492] 
2025-10-07 16:38:12.051236: Epoch time: 159.67 s 
2025-10-07 16:38:13.799242:  
2025-10-07 16:38:13.799448: Epoch 122 
2025-10-07 16:38:13.799562: Current learning rate: 0.00429 
2025-10-07 16:40:53.491894: train_loss -0.8872 
2025-10-07 16:40:53.492252: val_loss -0.7635 
2025-10-07 16:40:53.492327: Pseudo dice [0.8422] 
2025-10-07 16:40:53.492414: Epoch time: 159.69 s 
2025-10-07 16:40:54.850944:  
2025-10-07 16:40:54.851144: Epoch 123 
2025-10-07 16:40:54.851277: Current learning rate: 0.00424 
2025-10-07 16:43:34.632328: train_loss -0.8852 
2025-10-07 16:43:34.632710: val_loss -0.7657 
2025-10-07 16:43:34.632797: Pseudo dice [0.845] 
2025-10-07 16:43:34.632886: Epoch time: 159.78 s 
2025-10-07 16:43:36.024306:  
2025-10-07 16:43:36.024630: Epoch 124 
2025-10-07 16:43:36.024788: Current learning rate: 0.00419 
2025-10-07 16:46:15.738742: train_loss -0.886 
2025-10-07 16:46:15.739117: val_loss -0.7673 
2025-10-07 16:46:15.739199: Pseudo dice [0.8445] 
2025-10-07 16:46:15.739294: Epoch time: 159.72 s 
2025-10-07 16:46:17.142221:  
2025-10-07 16:46:17.142457: Epoch 125 
2025-10-07 16:46:17.142629: Current learning rate: 0.00414 
2025-10-07 16:48:57.150999: train_loss -0.8862 
2025-10-07 16:48:57.151371: val_loss -0.7549 
2025-10-07 16:48:57.151448: Pseudo dice [0.8369] 
2025-10-07 16:48:57.151547: Epoch time: 160.01 s 
2025-10-07 16:48:58.504981:  
2025-10-07 16:48:58.505189: Epoch 126 
2025-10-07 16:48:58.505308: Current learning rate: 0.00409 
2025-10-07 16:51:38.130546: train_loss -0.8819 
2025-10-07 16:51:38.130925: val_loss -0.7683 
2025-10-07 16:51:38.131003: Pseudo dice [0.8459] 
2025-10-07 16:51:38.131088: Epoch time: 159.63 s 
2025-10-07 16:51:39.501372:  
2025-10-07 16:51:39.501587: Epoch 127 
2025-10-07 16:51:39.501708: Current learning rate: 0.00404 
2025-10-07 16:54:19.184865: train_loss -0.8872 
2025-10-07 16:54:19.185268: val_loss -0.7648 
2025-10-07 16:54:19.185349: Pseudo dice [0.8485] 
2025-10-07 16:54:19.185438: Epoch time: 159.68 s 
2025-10-07 16:54:20.557455:  
2025-10-07 16:54:20.557664: Epoch 128 
2025-10-07 16:54:20.557794: Current learning rate: 0.00399 
2025-10-07 16:57:00.429914: train_loss -0.888 
2025-10-07 16:57:00.430292: val_loss -0.7568 
2025-10-07 16:57:00.430368: Pseudo dice [0.8364] 
2025-10-07 16:57:00.430464: Epoch time: 159.87 s 
2025-10-07 16:57:01.792981:  
2025-10-07 16:57:01.793192: Epoch 129 
2025-10-07 16:57:01.793308: Current learning rate: 0.00394 
2025-10-07 16:59:41.577978: train_loss -0.8876 
2025-10-07 16:59:41.578309: val_loss -0.7619 
2025-10-07 16:59:41.578389: Pseudo dice [0.843] 
2025-10-07 16:59:41.578474: Epoch time: 159.79 s 
2025-10-07 16:59:43.017498:  
2025-10-07 16:59:43.017745: Epoch 130 
2025-10-07 16:59:43.017871: Current learning rate: 0.00389 
2025-10-07 17:02:22.829876: train_loss -0.8825 
2025-10-07 17:02:22.830239: val_loss -0.7667 
2025-10-07 17:02:22.830315: Pseudo dice [0.8443] 
2025-10-07 17:02:22.830400: Epoch time: 159.81 s 
2025-10-07 17:02:24.209244:  
2025-10-07 17:02:24.209462: Epoch 131 
2025-10-07 17:02:24.209593: Current learning rate: 0.00384 
2025-10-07 17:05:03.942044: train_loss -0.8892 
2025-10-07 17:05:03.942396: val_loss -0.7533 
2025-10-07 17:05:03.942497: Pseudo dice [0.8402] 
2025-10-07 17:05:03.942597: Epoch time: 159.73 s 
2025-10-07 17:05:05.405858:  
2025-10-07 17:05:05.406048: Epoch 132 
2025-10-07 17:05:05.406168: Current learning rate: 0.00379 
2025-10-07 17:07:45.517762: train_loss -0.8902 
2025-10-07 17:07:45.518161: val_loss -0.757 
2025-10-07 17:07:45.518242: Pseudo dice [0.8379] 
2025-10-07 17:07:45.518331: Epoch time: 160.11 s 
2025-10-07 17:07:47.047690:  
2025-10-07 17:07:47.047891: Epoch 133 
2025-10-07 17:07:47.048012: Current learning rate: 0.00374 
2025-10-07 17:10:27.616224: train_loss -0.892 
2025-10-07 17:10:27.616845: val_loss -0.7612 
2025-10-07 17:10:27.616986: Pseudo dice [0.8427] 
2025-10-07 17:10:27.617088: Epoch time: 160.57 s 
2025-10-07 17:10:29.564228:  
2025-10-07 17:10:29.564491: Epoch 134 
2025-10-07 17:10:29.564615: Current learning rate: 0.00369 
2025-10-07 17:13:09.930247: train_loss -0.8902 
2025-10-07 17:13:09.930637: val_loss -0.7528 
2025-10-07 17:13:09.930736: Pseudo dice [0.8372] 
2025-10-07 17:13:09.930840: Epoch time: 160.37 s 
2025-10-07 17:13:11.467934:  
2025-10-07 17:13:11.468151: Epoch 135 
2025-10-07 17:13:11.468271: Current learning rate: 0.00364 
2025-10-07 17:15:51.748321: train_loss -0.8886 
2025-10-07 17:15:51.748722: val_loss -0.7619 
2025-10-07 17:15:51.748822: Pseudo dice [0.844] 
2025-10-07 17:15:51.748929: Epoch time: 160.28 s 
2025-10-07 17:15:53.336422:  
2025-10-07 17:15:53.336684: Epoch 136 
2025-10-07 17:15:53.336809: Current learning rate: 0.00359 
2025-10-07 17:18:33.642321: train_loss -0.8928 
2025-10-07 17:18:33.642740: val_loss -0.7634 
2025-10-07 17:18:33.642861: Pseudo dice [0.8458] 
2025-10-07 17:18:33.642969: Epoch time: 160.31 s 
2025-10-07 17:18:35.291515:  
2025-10-07 17:18:35.291799: Epoch 137 
2025-10-07 17:18:35.291930: Current learning rate: 0.00354 
2025-10-07 17:21:15.722489: train_loss -0.8873 
2025-10-07 17:21:15.722914: val_loss -0.7699 
2025-10-07 17:21:15.723018: Pseudo dice [0.8529] 
2025-10-07 17:21:15.723114: Epoch time: 160.43 s 
2025-10-07 17:21:17.299375:  
2025-10-07 17:21:17.299643: Epoch 138 
2025-10-07 17:21:17.299778: Current learning rate: 0.00349 
2025-10-07 17:23:57.535186: train_loss -0.8924 
2025-10-07 17:23:57.535564: val_loss -0.7656 
2025-10-07 17:23:57.535729: Pseudo dice [0.8478] 
2025-10-07 17:23:57.535828: Epoch time: 160.24 s 
2025-10-07 17:23:59.162740:  
2025-10-07 17:23:59.162984: Epoch 139 
2025-10-07 17:23:59.163114: Current learning rate: 0.00343 
2025-10-07 17:26:39.528849: train_loss -0.8914 
2025-10-07 17:26:39.529277: val_loss -0.7727 
2025-10-07 17:26:39.529366: Pseudo dice [0.8525] 
2025-10-07 17:26:39.529462: Epoch time: 160.37 s 
2025-10-07 17:26:41.122719:  
2025-10-07 17:26:41.123048: Epoch 140 
2025-10-07 17:26:41.123191: Current learning rate: 0.00338 
2025-10-07 17:29:21.295838: train_loss -0.8895 
2025-10-07 17:29:21.296264: val_loss -0.7545 
2025-10-07 17:29:21.296349: Pseudo dice [0.8398] 
2025-10-07 17:29:21.296453: Epoch time: 160.17 s 
2025-10-07 17:29:22.937504:  
2025-10-07 17:29:22.937729: Epoch 141 
2025-10-07 17:29:22.937883: Current learning rate: 0.00333 
2025-10-07 17:32:03.485921: train_loss -0.8925 
2025-10-07 17:32:03.486321: val_loss -0.7588 
2025-10-07 17:32:03.486443: Pseudo dice [0.8412] 
2025-10-07 17:32:03.486543: Epoch time: 160.55 s 
2025-10-07 17:32:05.077238:  
2025-10-07 17:32:05.077474: Epoch 142 
2025-10-07 17:32:05.077660: Current learning rate: 0.00328 
2025-10-07 17:34:45.414158: train_loss -0.8943 
2025-10-07 17:34:45.414556: val_loss -0.7663 
2025-10-07 17:34:45.414644: Pseudo dice [0.8476] 
2025-10-07 17:34:45.414753: Epoch time: 160.34 s 
2025-10-07 17:34:46.938800:  
2025-10-07 17:34:46.939235: Epoch 143 
2025-10-07 17:34:46.939368: Current learning rate: 0.00323 
2025-10-07 17:37:27.353385: train_loss -0.8898 
2025-10-07 17:37:27.353819: val_loss -0.7593 
2025-10-07 17:37:27.353907: Pseudo dice [0.8448] 
2025-10-07 17:37:27.353999: Epoch time: 160.42 s 
2025-10-07 17:37:29.265352:  
2025-10-07 17:37:29.265613: Epoch 144 
2025-10-07 17:37:29.265774: Current learning rate: 0.00318 
2025-10-07 17:40:09.585510: train_loss -0.8965 
2025-10-07 17:40:09.585914: val_loss -0.7643 
2025-10-07 17:40:09.585998: Pseudo dice [0.8477] 
2025-10-07 17:40:09.586437: Epoch time: 160.32 s 
2025-10-07 17:40:11.137884:  
2025-10-07 17:40:11.138099: Epoch 145 
2025-10-07 17:40:11.138221: Current learning rate: 0.00313 
2025-10-07 17:42:51.782443: train_loss -0.8973 
2025-10-07 17:42:51.782839: val_loss -0.7521 
2025-10-07 17:42:51.782922: Pseudo dice [0.8412] 
2025-10-07 17:42:51.783018: Epoch time: 160.65 s 
2025-10-07 17:42:53.334167:  
2025-10-07 17:42:53.334399: Epoch 146 
2025-10-07 17:42:53.334523: Current learning rate: 0.00308 
2025-10-07 17:45:33.806084: train_loss -0.8922 
2025-10-07 17:45:33.806511: val_loss -0.7538 
2025-10-07 17:45:33.806596: Pseudo dice [0.8386] 
2025-10-07 17:45:33.806710: Epoch time: 160.47 s 
2025-10-07 17:45:35.396148:  
2025-10-07 17:45:35.396441: Epoch 147 
2025-10-07 17:45:35.396575: Current learning rate: 0.00303 
2025-10-07 17:48:15.924918: train_loss -0.8951 
2025-10-07 17:48:15.925352: val_loss -0.7662 
2025-10-07 17:48:15.925497: Pseudo dice [0.8503] 
2025-10-07 17:48:15.925601: Epoch time: 160.53 s 
2025-10-07 17:48:17.517623:  
2025-10-07 17:48:17.518025: Epoch 148 
2025-10-07 17:48:17.518171: Current learning rate: 0.00297 
2025-10-07 17:50:58.584407: train_loss -0.8944 
2025-10-07 17:50:58.584935: val_loss -0.7596 
2025-10-07 17:50:58.585073: Pseudo dice [0.84] 
2025-10-07 17:50:58.585177: Epoch time: 161.07 s 
2025-10-07 17:51:00.312337:  
2025-10-07 17:51:00.312827: Epoch 149 
2025-10-07 17:51:00.313015: Current learning rate: 0.00292 
2025-10-07 17:53:41.529543: train_loss -0.8943 
2025-10-07 17:53:41.530060: val_loss -0.7523 
2025-10-07 17:53:41.530161: Pseudo dice [0.8378] 
2025-10-07 17:53:41.530259: Epoch time: 161.22 s 
2025-10-07 17:53:43.527392:  
2025-10-07 17:53:43.527624: Epoch 150 
2025-10-07 17:53:43.527763: Current learning rate: 0.00287 
2025-10-07 17:56:24.444941: train_loss -0.8947 
2025-10-07 17:56:24.445359: val_loss -0.7493 
2025-10-07 17:56:24.445504: Pseudo dice [0.8328] 
2025-10-07 17:56:24.445615: Epoch time: 160.92 s 
2025-10-07 17:56:25.968848:  
2025-10-07 17:56:25.969123: Epoch 151 
2025-10-07 17:56:25.969258: Current learning rate: 0.00282 
2025-10-07 17:59:06.533208: train_loss -0.8976 
2025-10-07 17:59:06.533598: val_loss -0.7594 
2025-10-07 17:59:06.533697: Pseudo dice [0.8435] 
2025-10-07 17:59:06.533790: Epoch time: 160.57 s 
2025-10-07 17:59:08.005350:  
2025-10-07 17:59:08.005581: Epoch 152 
2025-10-07 17:59:08.005713: Current learning rate: 0.00277 
2025-10-07 18:01:48.477830: train_loss -0.8949 
2025-10-07 18:01:48.478208: val_loss -0.7655 
2025-10-07 18:01:48.478294: Pseudo dice [0.8476] 
2025-10-07 18:01:48.478405: Epoch time: 160.47 s 
2025-10-07 18:01:49.983917:  
2025-10-07 18:01:49.984198: Epoch 153 
2025-10-07 18:01:49.984348: Current learning rate: 0.00272 
2025-10-07 18:04:30.652891: train_loss -0.8972 
2025-10-07 18:04:30.653276: val_loss -0.7619 
2025-10-07 18:04:30.653363: Pseudo dice [0.8486] 
2025-10-07 18:04:30.653543: Epoch time: 160.67 s 
2025-10-07 18:04:32.301906:  
2025-10-07 18:04:32.302204: Epoch 154 
2025-10-07 18:04:32.302371: Current learning rate: 0.00266 
2025-10-07 18:07:13.400414: train_loss -0.8986 
2025-10-07 18:07:13.400816: val_loss -0.7721 
2025-10-07 18:07:13.400898: Pseudo dice [0.8545] 
2025-10-07 18:07:13.400996: Epoch time: 161.1 s 
2025-10-07 18:07:15.765580:  
2025-10-07 18:07:15.766036: Epoch 155 
2025-10-07 18:07:15.766212: Current learning rate: 0.00261 
2025-10-07 18:09:57.049028: train_loss -0.8959 
2025-10-07 18:09:57.049499: val_loss -0.7575 
2025-10-07 18:09:57.049585: Pseudo dice [0.8416] 
2025-10-07 18:09:57.049689: Epoch time: 161.29 s 
2025-10-07 18:09:58.707823:  
2025-10-07 18:09:58.708112: Epoch 156 
2025-10-07 18:09:58.708259: Current learning rate: 0.00256 
2025-10-07 18:12:40.108523: train_loss -0.8986 
2025-10-07 18:12:40.108966: val_loss -0.7682 
2025-10-07 18:12:40.109156: Pseudo dice [0.8499] 
2025-10-07 18:12:40.109284: Epoch time: 161.4 s 
2025-10-07 18:12:41.734365:  
2025-10-07 18:12:41.734849: Epoch 157 
2025-10-07 18:12:41.734987: Current learning rate: 0.00251 
2025-10-07 18:15:22.683322: train_loss -0.8972 
2025-10-07 18:15:22.683727: val_loss -0.768 
2025-10-07 18:15:22.683831: Pseudo dice [0.8508] 
2025-10-07 18:15:22.683933: Epoch time: 160.95 s 
2025-10-07 18:15:24.258683:  
2025-10-07 18:15:24.259012: Epoch 158 
2025-10-07 18:15:24.259145: Current learning rate: 0.00245 
2025-10-07 18:18:05.685368: train_loss -0.9022 
2025-10-07 18:18:05.685868: val_loss -0.756 
2025-10-07 18:18:05.685954: Pseudo dice [0.8427] 
2025-10-07 18:18:05.686046: Epoch time: 161.43 s 
2025-10-07 18:18:07.435288:  
2025-10-07 18:18:07.435575: Epoch 159 
2025-10-07 18:18:07.435719: Current learning rate: 0.0024 
2025-10-07 18:20:49.759197: train_loss -0.9025 
2025-10-07 18:20:49.759730: val_loss -0.7573 
2025-10-07 18:20:49.759842: Pseudo dice [0.8416] 
2025-10-07 18:20:49.759964: Epoch time: 162.33 s 
2025-10-07 18:20:51.439042:  
2025-10-07 18:20:51.439347: Epoch 160 
2025-10-07 18:20:51.439507: Current learning rate: 0.00235 
2025-10-07 18:23:34.116641: train_loss -0.9031 
2025-10-07 18:23:34.117153: val_loss -0.7718 
2025-10-07 18:23:34.117236: Pseudo dice [0.854] 
2025-10-07 18:23:34.117339: Epoch time: 162.68 s 
2025-10-07 18:23:35.736986:  
2025-10-07 18:23:35.737261: Epoch 161 
2025-10-07 18:23:35.737388: Current learning rate: 0.0023 
2025-10-07 18:26:17.812401: train_loss -0.902 
2025-10-07 18:26:17.812850: val_loss -0.7594 
2025-10-07 18:26:17.813066: Pseudo dice [0.8455] 
2025-10-07 18:26:17.813182: Epoch time: 162.08 s 
2025-10-07 18:26:19.451192:  
2025-10-07 18:26:19.451514: Epoch 162 
2025-10-07 18:26:19.451669: Current learning rate: 0.00224 
2025-10-07 18:29:00.571008: train_loss -0.8995 
2025-10-07 18:29:00.571430: val_loss -0.7512 
2025-10-07 18:29:00.571514: Pseudo dice [0.8381] 
2025-10-07 18:29:00.571605: Epoch time: 161.12 s 
2025-10-07 18:29:02.158227:  
2025-10-07 18:29:02.158507: Epoch 163 
2025-10-07 18:29:02.158664: Current learning rate: 0.00219 
2025-10-07 18:31:42.851482: train_loss -0.9019 
2025-10-07 18:31:42.851904: val_loss -0.7542 
2025-10-07 18:31:42.851987: Pseudo dice [0.8407] 
2025-10-07 18:31:42.852090: Epoch time: 160.69 s 
2025-10-07 18:31:44.509899:  
2025-10-07 18:31:44.510117: Epoch 164 
2025-10-07 18:31:44.510244: Current learning rate: 0.00214 
2025-10-07 18:34:25.362889: train_loss -0.9021 
2025-10-07 18:34:25.363303: val_loss -0.7592 
2025-10-07 18:34:25.363397: Pseudo dice [0.8458] 
2025-10-07 18:34:25.363516: Epoch time: 160.85 s 
2025-10-07 18:34:26.891111:  
2025-10-07 18:34:26.891346: Epoch 165 
2025-10-07 18:34:26.891479: Current learning rate: 0.00208 
2025-10-07 18:37:07.996017: train_loss -0.9021 
2025-10-07 18:37:07.996524: val_loss -0.7708 
2025-10-07 18:37:07.996612: Pseudo dice [0.8531] 
2025-10-07 18:37:07.996722: Epoch time: 161.11 s 
2025-10-07 18:37:10.217384:  
2025-10-07 18:37:10.217726: Epoch 166 
2025-10-07 18:37:10.217880: Current learning rate: 0.00203 
2025-10-07 18:39:52.017527: train_loss -0.9049 
2025-10-07 18:39:52.017946: val_loss -0.7604 
2025-10-07 18:39:52.018043: Pseudo dice [0.8471] 
2025-10-07 18:39:52.018155: Epoch time: 161.8 s 
2025-10-07 18:39:53.583187:  
2025-10-07 18:39:53.583558: Epoch 167 
2025-10-07 18:39:53.583715: Current learning rate: 0.00198 
2025-10-07 18:42:35.022120: train_loss -0.9034 
2025-10-07 18:42:35.022537: val_loss -0.7539 
2025-10-07 18:42:35.022637: Pseudo dice [0.8443] 
2025-10-07 18:42:35.022746: Epoch time: 161.44 s 
2025-10-07 18:42:36.575953:  
2025-10-07 18:42:36.576187: Epoch 168 
2025-10-07 18:42:36.576313: Current learning rate: 0.00192 
2025-10-07 18:45:17.844257: train_loss -0.9024 
2025-10-07 18:45:17.844664: val_loss -0.7568 
2025-10-07 18:45:17.844766: Pseudo dice [0.842] 
2025-10-07 18:45:17.844937: Epoch time: 161.27 s 
2025-10-07 18:45:19.398773:  
2025-10-07 18:45:19.399026: Epoch 169 
2025-10-07 18:45:19.399152: Current learning rate: 0.00187 
2025-10-07 18:48:00.506382: train_loss -0.9048 
2025-10-07 18:48:00.506822: val_loss -0.756 
2025-10-07 18:48:00.506921: Pseudo dice [0.8456] 
2025-10-07 18:48:00.507023: Epoch time: 161.11 s 
2025-10-07 18:48:02.073887:  
2025-10-07 18:48:02.074146: Epoch 170 
2025-10-07 18:48:02.074275: Current learning rate: 0.00181 
2025-10-07 18:50:42.904959: train_loss -0.9044 
2025-10-07 18:50:42.905341: val_loss -0.7417 
2025-10-07 18:50:42.905424: Pseudo dice [0.8331] 
2025-10-07 18:50:42.905848: Epoch time: 160.83 s 
2025-10-07 18:50:44.386587:  
2025-10-07 18:50:44.386838: Epoch 171 
2025-10-07 18:50:44.386969: Current learning rate: 0.00176 
2025-10-07 18:53:24.807537: train_loss -0.9035 
2025-10-07 18:53:24.807925: val_loss -0.7635 
2025-10-07 18:53:24.808003: Pseudo dice [0.8487] 
2025-10-07 18:53:24.808094: Epoch time: 160.42 s 
2025-10-07 18:53:26.252262:  
2025-10-07 18:53:26.252474: Epoch 172 
2025-10-07 18:53:26.252591: Current learning rate: 0.0017 
2025-10-07 18:56:06.370742: train_loss -0.9031 
2025-10-07 18:56:06.371119: val_loss -0.759 
2025-10-07 18:56:06.371209: Pseudo dice [0.8466] 
2025-10-07 18:56:06.371302: Epoch time: 160.12 s 
2025-10-07 18:56:07.845480:  
2025-10-07 18:56:07.845703: Epoch 173 
2025-10-07 18:56:07.845828: Current learning rate: 0.00165 
2025-10-07 18:58:48.037383: train_loss -0.9025 
2025-10-07 18:58:48.037807: val_loss -0.7667 
2025-10-07 18:58:48.037908: Pseudo dice [0.8508] 
2025-10-07 18:58:48.038058: Epoch time: 160.19 s 
2025-10-07 18:58:49.532565:  
2025-10-07 18:58:49.532805: Epoch 174 
2025-10-07 18:58:49.532933: Current learning rate: 0.00159 
2025-10-07 19:01:29.869247: train_loss -0.9015 
2025-10-07 19:01:29.869620: val_loss -0.7577 
2025-10-07 19:01:29.869706: Pseudo dice [0.8462] 
2025-10-07 19:01:29.869800: Epoch time: 160.34 s 
2025-10-07 19:01:31.356657:  
2025-10-07 19:01:31.356864: Epoch 175 
2025-10-07 19:01:31.357011: Current learning rate: 0.00154 
2025-10-07 19:04:11.597146: train_loss -0.9046 
2025-10-07 19:04:11.597528: val_loss -0.7491 
2025-10-07 19:04:11.597611: Pseudo dice [0.8398] 
2025-10-07 19:04:11.597724: Epoch time: 160.24 s 
2025-10-07 19:04:13.101022:  
2025-10-07 19:04:13.101221: Epoch 176 
2025-10-07 19:04:13.101336: Current learning rate: 0.00148 
2025-10-07 19:06:53.367937: train_loss -0.9031 
2025-10-07 19:06:53.368281: val_loss -0.751 
2025-10-07 19:06:53.368361: Pseudo dice [0.8435] 
2025-10-07 19:06:53.368483: Epoch time: 160.27 s 
2025-10-07 19:06:55.203101:  
2025-10-07 19:06:55.203327: Epoch 177 
2025-10-07 19:06:55.203458: Current learning rate: 0.00143 
2025-10-07 19:09:35.498693: train_loss -0.903 
2025-10-07 19:09:35.499131: val_loss -0.7547 
2025-10-07 19:09:35.499223: Pseudo dice [0.8398] 
2025-10-07 19:09:35.499316: Epoch time: 160.3 s 
2025-10-07 19:09:36.994588:  
2025-10-07 19:09:36.994906: Epoch 178 
2025-10-07 19:09:36.995033: Current learning rate: 0.00137 
2025-10-07 19:12:17.464567: train_loss -0.9051 
2025-10-07 19:12:17.465019: val_loss -0.7518 
2025-10-07 19:12:17.465113: Pseudo dice [0.8406] 
2025-10-07 19:12:17.465214: Epoch time: 160.47 s 
2025-10-07 19:12:18.929422:  
2025-10-07 19:12:18.929645: Epoch 179 
2025-10-07 19:12:18.929780: Current learning rate: 0.00132 
2025-10-07 19:14:59.161287: train_loss -0.906 
2025-10-07 19:14:59.161676: val_loss -0.7494 
2025-10-07 19:14:59.161761: Pseudo dice [0.8395] 
2025-10-07 19:14:59.161887: Epoch time: 160.23 s 
2025-10-07 19:15:00.674045:  
2025-10-07 19:15:00.674277: Epoch 180 
2025-10-07 19:15:00.674409: Current learning rate: 0.00126 
2025-10-07 19:17:41.260140: train_loss -0.906 
2025-10-07 19:17:41.260574: val_loss -0.7659 
2025-10-07 19:17:41.260669: Pseudo dice [0.8528] 
2025-10-07 19:17:41.260766: Epoch time: 160.59 s 
2025-10-07 19:17:42.816834:  
2025-10-07 19:17:42.817100: Epoch 181 
2025-10-07 19:17:42.817235: Current learning rate: 0.0012 
2025-10-07 19:20:23.548517: train_loss -0.9101 
2025-10-07 19:20:23.548906: val_loss -0.7558 
2025-10-07 19:20:23.548995: Pseudo dice [0.8433] 
2025-10-07 19:20:23.549099: Epoch time: 160.73 s 
2025-10-07 19:20:25.058257:  
2025-10-07 19:20:25.058531: Epoch 182 
2025-10-07 19:20:25.058711: Current learning rate: 0.00115 
2025-10-07 19:23:05.904694: train_loss -0.9095 
2025-10-07 19:23:05.905101: val_loss -0.7417 
2025-10-07 19:23:05.905180: Pseudo dice [0.8361] 
2025-10-07 19:23:05.905286: Epoch time: 160.85 s 
2025-10-07 19:23:07.475278:  
2025-10-07 19:23:07.475502: Epoch 183 
2025-10-07 19:23:07.475632: Current learning rate: 0.00109 
2025-10-07 19:25:48.139251: train_loss -0.9043 
2025-10-07 19:25:48.139654: val_loss -0.7512 
2025-10-07 19:25:48.139750: Pseudo dice [0.8404] 
2025-10-07 19:25:48.139858: Epoch time: 160.67 s 
2025-10-07 19:25:49.601573:  
2025-10-07 19:25:49.601822: Epoch 184 
2025-10-07 19:25:49.601956: Current learning rate: 0.00103 
2025-10-07 19:28:30.386521: train_loss -0.908 
2025-10-07 19:28:30.386950: val_loss -0.7625 
2025-10-07 19:28:30.387031: Pseudo dice [0.8498] 
2025-10-07 19:28:30.387196: Epoch time: 160.79 s 
2025-10-07 19:28:31.903455:  
2025-10-07 19:28:31.903761: Epoch 185 
2025-10-07 19:28:31.903899: Current learning rate: 0.00097 
2025-10-07 19:31:12.444369: train_loss -0.9066 
2025-10-07 19:31:12.444798: val_loss -0.7729 
2025-10-07 19:31:12.444878: Pseudo dice [0.8531] 
2025-10-07 19:31:12.444983: Epoch time: 160.54 s 
2025-10-07 19:31:14.021154:  
2025-10-07 19:31:14.021510: Epoch 186 
2025-10-07 19:31:14.021667: Current learning rate: 0.00091 
2025-10-07 19:33:54.457334: train_loss -0.9061 
2025-10-07 19:33:54.457764: val_loss -0.7586 
2025-10-07 19:33:54.457858: Pseudo dice [0.8481] 
2025-10-07 19:33:54.457955: Epoch time: 160.44 s 
2025-10-07 19:33:55.907347:  
2025-10-07 19:33:55.907548: Epoch 187 
2025-10-07 19:33:55.907683: Current learning rate: 0.00085 
2025-10-07 19:36:36.303786: train_loss -0.9102 
2025-10-07 19:36:36.304163: val_loss -0.7469 
2025-10-07 19:36:36.304242: Pseudo dice [0.8366] 
2025-10-07 19:36:36.304336: Epoch time: 160.4 s 
2025-10-07 19:36:37.755609:  
2025-10-07 19:36:37.755846: Epoch 188 
2025-10-07 19:36:37.755979: Current learning rate: 0.00079 
2025-10-07 19:39:17.964491: train_loss -0.9088 
2025-10-07 19:39:17.964909: val_loss -0.7671 
2025-10-07 19:39:17.964992: Pseudo dice [0.8535] 
2025-10-07 19:39:17.965082: Epoch time: 160.21 s 
2025-10-07 19:39:19.924756:  
2025-10-07 19:39:19.925039: Epoch 189 
2025-10-07 19:39:19.925171: Current learning rate: 0.00074 
2025-10-07 19:42:00.286599: train_loss -0.9061 
2025-10-07 19:42:00.287024: val_loss -0.7486 
2025-10-07 19:42:00.287107: Pseudo dice [0.8392] 
2025-10-07 19:42:00.287197: Epoch time: 160.36 s 
2025-10-07 19:42:01.746972:  
2025-10-07 19:42:01.747204: Epoch 190 
2025-10-07 19:42:01.747329: Current learning rate: 0.00067 
2025-10-07 19:44:41.843212: train_loss -0.9102 
2025-10-07 19:44:41.843593: val_loss -0.7628 
2025-10-07 19:44:41.843679: Pseudo dice [0.8475] 
2025-10-07 19:44:41.843790: Epoch time: 160.1 s 
2025-10-07 19:44:43.354327:  
2025-10-07 19:44:43.354576: Epoch 191 
2025-10-07 19:44:43.354710: Current learning rate: 0.00061 
2025-10-07 19:47:23.519813: train_loss -0.9105 
2025-10-07 19:47:23.520234: val_loss -0.7639 
2025-10-07 19:47:23.520313: Pseudo dice [0.8497] 
2025-10-07 19:47:23.520400: Epoch time: 160.17 s 
2025-10-07 19:47:25.092471:  
2025-10-07 19:47:25.092770: Epoch 192 
2025-10-07 19:47:25.092899: Current learning rate: 0.00055 
2025-10-07 19:50:05.353281: train_loss -0.9086 
2025-10-07 19:50:05.353690: val_loss -0.7616 
2025-10-07 19:50:05.353781: Pseudo dice [0.8502] 
2025-10-07 19:50:05.353874: Epoch time: 160.26 s 
2025-10-07 19:50:06.907428:  
2025-10-07 19:50:06.907733: Epoch 193 
2025-10-07 19:50:06.907868: Current learning rate: 0.00049 
2025-10-07 19:52:47.441386: train_loss -0.909 
2025-10-07 19:52:47.441803: val_loss -0.758 
2025-10-07 19:52:47.441896: Pseudo dice [0.8486] 
2025-10-07 19:52:47.441989: Epoch time: 160.54 s 
2025-10-07 19:52:47.442055: Yayy! New best EMA pseudo Dice: 0.8461 
2025-10-07 19:52:49.442598:  
2025-10-07 19:52:49.442904: Epoch 194 
2025-10-07 19:52:49.443028: Current learning rate: 0.00043 
2025-10-07 19:55:29.760317: train_loss -0.9092 
2025-10-07 19:55:29.760740: val_loss -0.76 
2025-10-07 19:55:29.760864: Pseudo dice [0.8429] 
2025-10-07 19:55:29.760981: Epoch time: 160.32 s 
2025-10-07 19:55:31.316252:  
2025-10-07 19:55:31.316557: Epoch 195 
2025-10-07 19:55:31.316702: Current learning rate: 0.00036 
2025-10-07 19:58:11.615670: train_loss -0.9062 
2025-10-07 19:58:11.616089: val_loss -0.7571 
2025-10-07 19:58:11.616202: Pseudo dice [0.8439] 
2025-10-07 19:58:11.616297: Epoch time: 160.3 s 
2025-10-07 19:58:13.255622:  
2025-10-07 19:58:13.255918: Epoch 196 
2025-10-07 19:58:13.256045: Current learning rate: 0.0003 
2025-10-07 20:00:53.782662: train_loss -0.9107 
2025-10-07 20:00:53.783301: val_loss -0.7621 
2025-10-07 20:00:53.783394: Pseudo dice [0.8493] 
2025-10-07 20:00:53.783499: Epoch time: 160.53 s 
2025-10-07 20:00:55.331291:  
2025-10-07 20:00:55.331535: Epoch 197 
2025-10-07 20:00:55.331667: Current learning rate: 0.00023 
2025-10-07 20:03:36.167381: train_loss -0.9108 
2025-10-07 20:03:36.167962: val_loss -0.7464 
2025-10-07 20:03:36.168049: Pseudo dice [0.8335] 
2025-10-07 20:03:36.168142: Epoch time: 160.84 s 
2025-10-07 20:03:37.705155:  
2025-10-07 20:03:37.705476: Epoch 198 
2025-10-07 20:03:37.705612: Current learning rate: 0.00016 
2025-10-07 20:06:18.343675: train_loss -0.9081 
2025-10-07 20:06:18.344090: val_loss -0.7539 
2025-10-07 20:06:18.344173: Pseudo dice [0.8447] 
2025-10-07 20:06:18.344262: Epoch time: 160.64 s 
2025-10-07 20:06:19.862404:  
2025-10-07 20:06:19.862835: Epoch 199 
2025-10-07 20:06:19.863047: Current learning rate: 8e-05 
2025-10-07 20:09:00.536550: train_loss -0.9084 
2025-10-07 20:09:00.536937: val_loss -0.7577 
2025-10-07 20:09:00.537024: Pseudo dice [0.8468] 
2025-10-07 20:09:00.537116: Epoch time: 160.68 s 
2025-10-07 20:09:03.483837: Training done. 
2025-10-07 20:09:03.808566: Using splits from existing split file: /home/rnga/tsdehaan/my-scratch/Data_nnUNet/nnUnet_preprocessed/Dataset001_AAA/splits_final.json 
2025-10-07 20:09:03.809561: The split file contains 5 splits. 
2025-10-07 20:09:03.809676: Desired fold for training: 0 
2025-10-07 20:09:03.809755: This split has 61 training and 16 validation cases. 
2025-10-07 20:09:03.810172: predicting IVIM_004 
2025-10-07 20:09:03.813232: IVIM_004, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:13.880569: predicting IVIM_011 
2025-10-07 20:09:13.882459: IVIM_011, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:14.418191: predicting IVIM_017 
2025-10-07 20:09:14.419951: IVIM_017, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:14.931297: predicting IVIM_036 
2025-10-07 20:09:14.932894: IVIM_036, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:15.457435: predicting IVIM_048 
2025-10-07 20:09:15.459148: IVIM_048, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:15.982043: predicting IVIM_060 
2025-10-07 20:09:15.983837: IVIM_060, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:19.732801: predicting IVIM_065 
2025-10-07 20:09:19.734601: IVIM_065, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:20.282543: predicting IVIM_070 
2025-10-07 20:09:20.284305: IVIM_070, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:20.875395: predicting IVIM_086 
2025-10-07 20:09:20.877081: IVIM_086, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:21.379039: predicting IVIM_122 
2025-10-07 20:09:21.380812: IVIM_122, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:21.883178: predicting IVIM_124 
2025-10-07 20:09:21.884801: IVIM_124, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:22.385767: predicting IVIM_132 
2025-10-07 20:09:22.387344: IVIM_132, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:22.889270: predicting IVIM_141 
2025-10-07 20:09:22.890967: IVIM_141, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:23.393080: predicting IVIM_145 
2025-10-07 20:09:23.394940: IVIM_145, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:23.892777: predicting IVIM_155 
2025-10-07 20:09:23.894581: IVIM_155, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:24.396594: predicting IVIM_158 
2025-10-07 20:09:24.399074: IVIM_158, shape torch.Size([1, 27, 168, 256]), rank 0 
2025-10-07 20:09:38.959692: Validation complete 
2025-10-07 20:09:38.959849: Mean Validation Dice:  0.8367445386801244 
